# Paper Reviews


## Introduction
This repository is a collection of short reviews of papers in Deep Learning. Reviews are based on papers which explore novel groundbreaking ideas or consist of theoretically rich concepts. A total of 2 short reviews are typically added each week which explore essential aspects of the work, its technical innovation and new questions and ideas raised by the work. Length of each review is 1 page. Each review is based on a fixed set of guidlines which are given [here](#guidlines). If you would like to contribute to the reviews then please read [this](#contributions).

## Available Paper Reviews

|Review Number|Paper Title|Author List|Review Link|Contributor|
|:-----------:|:---------:|:---------:|:---------:|:---------:|
|1|[Action and Perception as Divergence Minimization](https://arxiv.org/pdf/2009.01791.pdf)|Danijar Hafner,Pedro A. Ortega,Jimmy Ba,Thomas Parr,Karl Friston,Nicolas Heess|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-01/main.pdf)|[@karush17](https://github.com/karush17)|
|2|[Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/pdf/1911.05722.pdf)|Kaiming He,Haoqi Fan,Yuxin Wu,Saining Xie,Ross Girshick|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-02/main.pdf)|[@karush17](https://github.com/karush17)|
|3|[When to use parametric models in reinforcement learning?](https://arxiv.org/pdf/1906.05243.pdf)|Hado van Hasselt, Matteo Hessel, John Aslanides|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-03/main.pdf)|[@karush17](https://github.com/karush17)|
|4|[Data-Efficient Image Recognition With Contrastive Predictive Coding](https://arxiv.org/pdf/1905.09272v2.pdf)|Olivier J. Henaff,Aravind Srinivas,Jeffrey De Fauw,Ali Razavi,Carl Doersch,S. M. Ali Eslami,Aaron van den Oord|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-04/main.pdf)|[@karush17](https://github.com/karush17)|
|5|[A Learning Algorithm for Boltzmann Machines](https://onlinelibrary.wiley.com/doi/pdf/10.1207/s15516709cog0901_7)|David H. Ackley,Geoffrey E. Hinton,Terrence J. Sejnowski|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-05/main.pdf)|[@karush17](https://github.com/karush17)|
|6|[Dependence Measures Bounding the Exploration Bias for General Measurements](https://arxiv.org/pdf/1612.05845.pdf)|Jiantao Jiao,Yanjun Han,Tsachy Weissman|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-06/main.pdf)|[@karush17](https://github.com/karush17)|
|7|[On Variational Bounds of Mutual Information](https://arxiv.org/pdf/1905.06922.pdf)|Ben Poole,Sherjil Ozair,Aaron van den Oord,Alexander A. Alemi,George Tucker|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-07/main.pdf)|[@karush17](https://github.com/karush17)|
|8|[Hindsight Credit Assignment](https://arxiv.org/pdf/1912.02503.pdf)|Anna Harutyunyan, Will Dabney, Thomas Mesnard, Nicolas Heess, Mohammad G. Azar, Bilal Piot, Hado van Hasselt, Satinder Singh, Greg Wayne, Doina Precup, Rémi Munos|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-08/main.pdf)|[@karush17](https://github.com/karush17)|
|9|[Learning a Contact-Adaptive Controller for Robust, Efficient Legged Locomotion](https://arxiv.org/pdf/2009.10019.pdf)|Xingye Da, Zhaoming Xie, David Hoeller, Byron Boots, Animashree Anandkumar, Yuke Zhu, Buck Babich, Animesh Garg|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-09/main.pdf)|[@karush17](https://github.com/karush17)|
|10|[Counterfactual Data Augmentation using Locally Factored Dynamics](https://arxiv.org/pdf/2007.02863.pdf)|Silviu Pitis, Elliot Creager, Animesh Garg|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-10/main.pdf)|[@karush17](https://github.com/karush17)|
|11|[LEAF: Latent Exploration Along the Frontier](https://arxiv.org/pdf/2005.10934.pdf)|Homanga Bharadhwaj, Animesh Garg, Florian Shkurti|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-11/main.pdf)|[@karush17](https://github.com/karush17)|
|12|[Cautious Adaptation For Reinforcement Learning in Safety-Critical Settings](https://arxiv.org/pdf/2008.06622.pdf)|Jesse Zhang, Brian Cheung, Chelsea Finn, Sergey Levine, Dinesh Jayaraman|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-12/main.pdf)|[@karush17](https://github.com/karush17)|
|13|[Model-Based Reinforcement Learning with Value-Targeted Regression](https://openreview.net/pdf?id=MGPm46WILav)|Zeyu Jia, Lin F. Yang, Csaba Szepesvari, Mengdi Wang|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-13/main.pdf)|[@karush17](https://github.com/karush17)|
|14|[Skill Transfer Via Partially Amortized Hierarchical Planning](https://openreview.net/pdf?id=jXe91kq3jAq)|Kevin Xie, Homanga Bharadhwaj, Danijar Hafner, Animesh Garg, Florian Shkurti|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-14/main.pdf)|[@karush17](https://github.com/karush17)|
|15|[Evaluating Agents Without Rewards](https://openreview.net/pdf?id=FoM-RnF6SNe)|Jimmy Ba, Danijar Hafner|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-15/main.pdf)|[@karush17](https://github.com/karush17)|
|16|[Conservative Safety Critics For Exploration](https://arxiv.org/pdf/2010.14497.pdf)|Homanga Bharadhwaj, Aviral Kumar, Nicholas Rhinehart, Sergey Levine, Florian Shkurti, Animesh Garg|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-16/main.pdf)|[@karush17](https://github.com/karush17)|
|17|[Mastering Atari with Discrete World Models](https://arxiv.org/pdf/2010.02193.pdf)|Danijar Hafner, Timothy Lillicrap, Mohammad Norouzi, Jimmy Ba|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-17/main.pdf)|[@karush17](https://github.com/karush17)|
|18|[Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/2006.10800.pdf)|Tabish Rashid, Gregory Farquhar, Bei Peng, Shimon Whiteson|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-18/main.pdf)|[@karush17](https://github.com/karush17)|
|&#x1F534; 19|[Continual Model-Based Reinforcement Learning with Hypernetworks](https://arxiv.org/pdf/2009.11997.pdf)|Yizhou Huang, Kevin Xie, Homanga Bharadhwaj, Florian Shkurti|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-19/main.pdf)|[@karush17](https://github.com/karush17)|
|20|[Model-Based Inverse Reinforcement Learning from Visual Demonstrations](https://arxiv.org/pdf/2010.09034.pdf)|Neha Das, Sarah Bechtle, Todor Davchev, Dinesh Jayaraman, Akshara Rai, Franziska Meier|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-20/main.pdf)|[@karush17](https://github.com/karush17)|
|21|[RODE: LEARNING ROLES TO DECOMPOSE MULTI-AGENT TASKS](https://arxiv.org/pdf/2010.01523.pdf)|Tonghan Wang, Tarun Gupta, Anuj Mahajan, Bei Peng, Shimon Whiteson, Chongjie Zhang|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-21/main.pdf)|[@karush17](https://github.com/karush17)|
|22|[THE ACT OF REMEMBERING: A STUDY IN PARTIALLY OBSERVABLE REINFORCEMENT LEARNING](https://arxiv.org/pdf/2010.01753.pdf)|Rodrigo Toro Icarte, Richard Valenzano, Toryn Q. Klassen, Phillip Christoffersen, Amir-massoud Farahmand, Sheila A. McIlraith|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-22/main.pdf)|[@karush17](https://github.com/karush17)|
|23|[An Inductive Bias for Distances: Neural Nets that Respect the Triangle Inequality](https://arxiv.org/pdf/2002.05825.pdf)|Silviu Pitis, Harris Chan, Kiarash Jamali, Jimmy Ba|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-23/main.pdf)|[@karush17](https://github.com/karush17)|
|24|[MAVEN: Multi-Agent Variational Exploration](https://arxiv.org/pdf/1910.07483.pdf)|Anuj Mahajan, Tabish Rashid, Mikayel Samvelyan, Shimon Whiteson|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-24/main.pdf)|[@karush17](https://github.com/karush17)|
|25|[Visual Imitation Made Easy](https://arxiv.org/pdf/2008.04899.pdf)|Sarah Young, Dhiraj Gandhi, Shubham Tulsiani, Abhinav Gupta, Pieter Abbeel, Lerrel Pinto|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-25/main.pdf)|[@karush17](https://github.com/karush17)|
|26|[“Other-Play” for Zero-Shot Coordination](https://arxiv.org/pdf/2003.02979.pdf)|Hengyuan Hu, Adam Lerer, Alex Peysakhovich, Jakob Foerster|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-26/main.pdf)|[@karush17](https://github.com/karush17)|
|27|[Using Fast Weights to Attend to the Recent Past](https://proceedings.neurips.cc/paper/2016/file/9f44e956e3a2b7b5598c625fcc802c36-Paper.pdf)|Jimmy Ba, Geoffrey Hinton, Volodymyr Mnih, Joel Z. Leibo, Catalin Ionescu|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-27/main.pdf)|[@karush17](https://github.com/karush17)|
|28|[γ-Models: Generative Temporal Difference Learning for Infinite-Horizon Prediction](https://arxiv.org/pdf/2010.14496.pdf)|Michael Janner, Igor Mordatch, Sergey Levine|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-28/main.pdf)|[@karush17](https://github.com/karush17)|
|29|[ROMA: Multi-Agent Reinforcement Learning with Emergent Roles](https://arxiv.org/pdf/2003.08039.pdf)|Tonghan Wang, Heng Dong, Victor Lesser, Chongjie Zhang|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-29/main.pdf)|[@karush17](https://github.com/karush17)|
|30|[Ridge Rider: Finding Diverse Solutions by Following Eigenvectors of the Hessian](https://arxiv.org/pdf/2011.06505.pdf)|Jack Parker-Holder, Luke Metz, Cinjon Resnick, Hengyuan Hu, Adam Lerer, Alistair Letcher,  Alex Peysakhovich, Aldo Pacchiano, Jakob Foerster|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-30/main.pdf)|[@karush17](https://github.com/karush17)|
|31|[Generalized Hindsight for Reinforcement Learning](https://arxiv.org/pdf/2011.06505.pdf)|Alexander C. Li, Lerrel Pinto, Pieter Abbeel|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-31/main.pdf)|[@karush17](https://github.com/karush17)|
|32|[Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors](https://arxiv.org/pdf/2011.06505.pdf)|Karl Pertsch, Oleh Rybkin, Frederik Ebert,
Chelsea Finn, Dinesh Jayaraman, Sergey Levine|[link](https://github.com/karush17/Paper-Reviews/blob/master/Review-32/main.pdf)|[@karush17](https://github.com/karush17)|


## <a name="guidlines"></a>Review Guidlines
This section outlines the guidlines which are used to write reviews for the repository. Note that these guidlines must be strictly followed for providing high quality reviews to the reader. 

### Paper Selection
Since Deep Learning is a fast-moving field, papers can span a broad variety of topics. In order to shorten the range of literature, papers must be selected using the following rules-  
* Any review paper, survey or a long article should not be considered since these are themselves a review of previous works and reviewing them would defeat the purpose of literature writing.
* Short papers, Journal papers and theoretical works are suitable as these present a single idea which may be of interest to the reader.
* Papers containing experimental results balanced with theory are encouraged as these validate the practical applications of the proposed methods.
* There is no constraint on the publication date and time of papers. However, papers which date back to the 'AI Winter' are highly encouraged since these provide insights which were never looked at for a very long time.
* Papers containing simply applications of pre-existing methods to various regimes are not preferred since they do not provide any new insights into the algorithm itself and only deal with its applicability.
* Workshop papers and incomplete works are also welcome as researchers can always build on these ideas.
* While there is no specific restriction on the content of papers, reviewer must consider fields in AI which are growing and require a new outlook, eg. Reinforcement Learning, Gradient-Free methods, Meta-Learning, Natural Language at Scale, Explainability, etc.


### Introduction
This section provides points on writing a good introduction for the review. Note that these review points are not strict and only serve as a guiding principle for drafting a good introduction.  
* The introduction should be a high-level idea of the paper and what the work deals with.
* The reviewer must refrain from going into any technical detail and highlight the broad idea of the work and its scope.
* No mathematical terms, definitions, technical explanations or algorithmic details should be provided to the reader.
* The main focus should be on the problem statement and how the method aims to solve this.
* A possible checklist of questions one might want to answer while writing a good introduction is as followed-
    - [ ] What is the main area of the work?
    - [ ] What are some of the open problems in this area?
    - [ ] What has been done so far to address these problems?
    - [ ] What still remains as the scope of this paper?
    - [ ] What does the paper propose?
    - [ ] How does the paper solve this problem?
    - [ ] What theoretical/practical insights does the work achieve?
    - [ ] What could have been (or is) done better to solve the problem?
* Key takeaway- Detail is your enemy!


### Methodology
This section deals with the proposed method and its essential aspects in solving the problem highlighted in the introduction section. Following points serve as a guide to writing this section-  
* The content must provide a brief overview of the method. This informs the reader about what he is getting into.
* Once an overview has been provided, the draft can start diving into the detail which should be highlighted intuitively.
* Mathematical details must be followed by words, complicated terminology must be explained intuitively using examples or instances from work.
* Reasons related to technical details and there usage must be provided to the reader. The whole point of reading a review is to crisply go over the details of the paper without wanting to read the entire text.
* While the draft should highlight the method and its details, it should also provide the reader with insights from the reviewer's point of view. These could consist of specific reasons for selecting a set of parameter values, usage of a specific technique existing in literature, novel contributions and the reason behind its usage and any improvements/changes from previous works.
* A possible checklist of constituents of this section is as followed-
    - [ ] Overview of the method and its details
    - [ ] Mathematical/technical details related to the algorithm and/or its implementations
    - [ ] Proper reasoning behind technical contributions
    - [ ] Detailed discussion of novel contributions
    - [ ] Differences/improvements and their reasons from previous literature
    - [ ] Critical insights into the method's applicability to practical scenarios
    - [ ] Reviewer's own discussion about the method and its components
* Key takeway- Intuition is king!


### Critical Analysis
The critical analysis section deals with the reviewer's analysis and understanding of the method. Specifically, this section should highlight what the reviewer thinks about the proposed approach, its strengths, weaknesses and potential areas of improvement and applicability. This is the most important section of the review since the reviewer needs to critically evaluate and comment on the technical aspects of the work. The following points should be kept in mind while writing a good critical analysis-
* One should evaluate all aspects of the work before diving into this section. A comprehensive analysis of the work is essential as it builds on the reviewer's understanding of the method.
* Once the complete details have been established, a proper structure for evaluation should be constructed. Typically, this structure should consist of comments on motivational aspects, strengths, weaknesses, novel contributions, applicability of the method, extensions and improvements of the method's components and their shortcomings. 
* The draft should be written in a critical yet formal manner. For instance, the reviewer must highlight the intriguing aspects of the algorithm and at the same time throw light on its critical parts in a decorous manner.
* Reviewer's comments should be their own and not focus on explaining the work. The main idea behind this section is to present your understanding of the text to the reader, not the text itself.
* A possible checklist of questions one may ask while writing this section is as followed-
    - [ ] Have all the aspects of the work been convered in an articulate manner?
    - [ ] What are the key components of the method?
    - [ ] What are the strengths, weaknesses, applications, extensions and shortcomings of these components?
    - [ ] How are these components novel in nature?
    - [ ] How can these components be used in theoretical/practical scenarios related to the area of work?
    - [ ] How can these components be improved and in theoretical/practical scenarios related to the area of work?
* Key takeway- Your own contributions matter!


### New Ideas/Questions
This section follows and builds upon the critical analysis section. The main idea behind this section is to highlight and examine the novel contributions of the proposed method and their contributions towards improving prior techniques. Another reason to study new ideas proposed by a paper is to identify potential directions of research and answer open questions from different perspectives. Following points may come in handy while writing this section-
* One should concisely summarize the novel contributions of the work (not more than 1-2 sentences).
* The summary should be followed by a critical analysis or a set of possible questions which maybe asked while using the novel aspects of the method.
* Since the focus is on novelty, reviewer may also be interested in asking questions related to other potential techniques and their applicability in place of the novel method.
* The section should conclude with brief comments on substitutes/extensions to the novel components and questions left unanswered (if any) in the work.
* A possible checklist of constituents of this section is as followed-
    - [ ] What is the novelty of the proposed method?
    - [ ] Can the novelty be used in other methods related to the area of work?
    - [ ] What are some of the potential substitutes to the novel contributions?
    - [ ] How would these compare to the novel contributions?
    - [ ] What are some of the questions answered/addressed by the novel contributions? 
    - [ ] What are some of the questions the method opens up? Is it suitable as a future research direction?
* Key takeway- Questions, Questions, Questions! 

### Conclusions
Lastly, the conclusions section should clearly and concisely sum up the review of the work. This section should consist of a crisp summary of all the previous sections and only highlight their most important aspects. The content of this section should be directed to someone who does not have enough time to read the review and only wishes to grab the essential points. A good conlusion could be written using the following points-
* The summary should start with a high level introductory note of the method, its usage and contributions. (not more 1-2 sentences)
* The summary should explore the novelty of the method, its implications and the resulting outcome achieved from the reviewer's point of view.
* The summary should walk over the key components of reviewer's evaluation and his comments on the method.
* The summary should conclude with a brief note of new ideas/questions introduced by the work and potential directions for future work.
* A possible checklist of questions the reviewer might ask himself while writing this section is as followed-
    - [ ] Have I summarized the method and its constituents in a concise manner?
    - [ ] Have I highlighted the novel aspects of the work for my reader?
    - [ ] Have I provided the key components of my review/analysis?
    - [ ] Have I paved the way for research by adding new ideas/questions?
* Key takeway- Just be done already! 


## <a name="contributions"></a>Contributions
*"No one can whistle a symphony. It takes a whole orchestra to play it."* – H.E. Luccock  

Collaboration is most welcome for this repository. If you believe that you would like to practice your research writing skills or would like to do a literature survey for your independent study, then feel free to hop in! Reviews in this repository follow a general LaTeX template which is available in the template folder. Furthermore, reviews written for the repository must follow the review guidlines which are available [here](#guidlines). Feel free to submit the paper and its review by opening a pull request.


