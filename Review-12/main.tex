
\documentclass[11pt,letterpaper]{article}
\usepackage{fullpage}
\usepackage[top=2cm, bottom=4.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\hypersetup{%
  colorlinks=true,
  linkcolor=blue,
  linkbordercolor={0 0 1}
}
\renewcommand\lstlistingname{Algorithm}
\renewcommand\lstlistlistingname{Algorithms}
\def\lstlistingautorefname{Alg.}

\lstdefinestyle{Python}{
    language        = Python,
    frame           = lines, 
    basicstyle      = \footnotesize,
    keywordstyle    = \color{blue},
    stringstyle     = \color{green},
    commentstyle    = \color{red}\ttfamily
}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}



\pagestyle{fancyplain}
\headheight 35pt
                 % ENTER REVIEW NUMBER HERE %
\chead{\textbf{\large Review-12}}
           % ################################### %

\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\begin{document}


                 % ENTER PAPER TITLE HERE %
\begin{center}
  \large{Cautious Adaptation For Reinforcement Learning in Safety-Critical Settings}
\end{center}
           % ################################### %

Real-world settings require the Reinforcement Learning (RL) agent to cautious yet optimal behavior. To that end, the work presents a Safety Critical Adaptation (SCA) framework which allows the agent to adapt to scenarios by executing a safe policy. The framework trains the agent in a non-safety critical simulation setting. Following pretraining, the agent is made to adapt safety-critical scenarios where catastrophic states penalize the agent heavily. The work further proposes a solution based on SCA framework in order to yield risk-averse policies for cautious adaptation. Cautious Adaptation in Reinforcement Learning (CARL) makes use of model-based RL to capture uncertainity and estimate risk followed by planning in sfety-critical settings to avoid catastrophic states. CARL empirically demonstrates risk-averse behavior with fewer failures in comparison to RL baselines. 


           
\end{document}
