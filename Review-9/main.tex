
\documentclass[11pt,letterpaper]{article}
\usepackage{fullpage}
\usepackage[top=2cm, bottom=4.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\hypersetup{%
  colorlinks=true,
  linkcolor=blue,
  linkbordercolor={0 0 1}
}
\renewcommand\lstlistingname{Algorithm}
\renewcommand\lstlistlistingname{Algorithms}
\def\lstlistingautorefname{Alg.}

\lstdefinestyle{Python}{
    language        = Python,
    frame           = lines, 
    basicstyle      = \footnotesize,
    keywordstyle    = \color{blue},
    stringstyle     = \color{green},
    commentstyle    = \color{red}\ttfamily
}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}



\pagestyle{fancyplain}
\headheight 35pt
                 % ENTER REVIEW NUMBER HERE %
\chead{\textbf{\large Review-9}}
           % ################################### %

\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\begin{document}


                 % ENTER PAPER TITLE HERE %
\begin{center}
  \large{Learning a Contact-Adaptive Controller for Robust,
  Efficient Legged Locomotion}
\end{center}
           % ################################### %

Robust controllers enable efficient qudruped locomotion which requires execution various complex gaits. The work proposes a hierarchical framework for robust control of a quadruped. The hierarchical system consists of a high level controller which makes use of Reinforcement Learning (RL) to select primitives. The low level controller learns contact adaptive behavior based on these primitives using Quadrtic Programming (QP). The end-result of hierarchical framework is a robust and energy-efficient physical robot controller which generalizes to tasks not seen during training.  

The work aims to tackle robustness in real-world controllers by unifying RL with a control-based approach. The high level controller makes use of an RL policy which is based on a variant of Double Q-learning. The policy learns to select primitve gaits which consist of swing and stand states defining the contact configuration of the four feet. This eliminates the need for computationally expensive model-based techniques which require the controller to build a model of contact states. Primitives selected by the high-level policy are used by the low-level controller which models torque control as a QP problem. The controller solves the QP for foot forces based on contact constraints, base pose dynamics and swing foot control heuristics. Swing and foot control give rise to foot forces which are converted to motor torques using feet positions Jacobian matrix. The framework is trained on a number of scenarios with varying speed of the moving surface, combinations of moving and static surfaces and different orientations of the quadruped. This results in energy-efficiency and generalization of the robot to unseen tasks such as frictionless surface.

The proposed hierarchical framework depicts improved robustness and energy-efficiency in comparison to baseline methods which are constructed from static high-level controllers. Additionally, Sim-to-Real experiments carried on the physical robot validate the robustness of the high and low-level controllers while walking forward and during leg perturbations. However, the energy-efficiency of the robot can be better evaluated by improving the design of experiments. For instance, the curious reader may ask that what would happen to the energy of the system if instead of keeping one surface static during training, both surfaces were moving? Moreover, how would the energy and robustness turn out if the movement was made intermittent? Leveraging a more thorough design choice for experiments would lead to a better evaluation of energy and robustness. 

Controlling qudruped locomotion in an efficient and robust manner in the real world is a challenging task. To that end, the work opens 2 new avenues for future work in this direction. Firstly, the design of contact-adaptive control can be extended to higher degrees of freedom and complex task spaces wherein the robot links can have multiple swing and stance states. Lastly, the hierarchical framework consisting of RL and adaptive control can accomodate more hierarchies. This would allow the robot to learn diverse contact-based behaviors such as angular contacts. 




\end{document}
